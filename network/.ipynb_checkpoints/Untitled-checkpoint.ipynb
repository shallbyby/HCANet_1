{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 6\n",
      "Output stride: 16\n",
      "Number of Input Channels: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/pytorch-1.3/lib/python3.6/site-packages/torch/nn/functional.py:2404: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, rate=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               dilation=rate, padding=rate, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.rate = rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, nInputChannels, block, layers, os=16, pretrained=False):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        if os == 16:\n",
    "            strides = [1, 2, 2, 1]\n",
    "            rates = [1, 1, 1, 2]\n",
    "            blocks = [1, 2, 4]\n",
    "        elif os == 8:\n",
    "            strides = [1, 2, 1, 1]\n",
    "            rates = [1, 1, 2, 2]\n",
    "            blocks = [1, 2, 1]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Modules\n",
    "        self.conv1 = nn.Conv2d(nInputChannels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=strides[0], rate=rates[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=strides[1], rate=rates[1])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=strides[2], rate=rates[2])\n",
    "        self.layer4 = self._make_MG_unit(block, 512, blocks=blocks, stride=strides[3], rate=rates[3])\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "        if pretrained:\n",
    "            self._load_pretrained_model()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, rate=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, rate, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_MG_unit(self, block, planes, blocks=[1,2,4], stride=1, rate=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, rate=blocks[0]*rate, downsample=downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, len(blocks)):\n",
    "            layers.append(block(self.inplanes, planes, stride=1, rate=blocks[i]*rate))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        low_level_feat = x\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x, low_level_feat\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _load_pretrained_model(self):\n",
    "        pretrain_dict = model_zoo.load_url('https://download.pytorch.org/models/resnet101-5d3b4d8f.pth')\n",
    "        model_dict = {}\n",
    "        state_dict = self.state_dict()\n",
    "        for k, v in pretrain_dict.items():\n",
    "            if k in state_dict:\n",
    "                model_dict[k] = v\n",
    "        state_dict.update(model_dict)\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "def ResNet101(nInputChannels=3, os=16, pretrained=False):\n",
    "    model = ResNet(nInputChannels, Bottleneck, [3, 4, 23, 3], os, pretrained=pretrained)\n",
    "    return model\n",
    "\n",
    "\n",
    "class ASPP_module(nn.Module):\n",
    "    def __init__(self, inplanes, planes, rate):\n",
    "        super(ASPP_module, self).__init__()\n",
    "        if rate == 1:\n",
    "            kernel_size = 1\n",
    "            padding = 0\n",
    "        else:\n",
    "            kernel_size = 3\n",
    "            padding = rate\n",
    "        self.atrous_convolution = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                                            stride=1, padding=padding, dilation=rate, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_convolution(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class DeepLabv3_plus(nn.Module):\n",
    "    def __init__(self, nInputChannels=3, n_classes=21, os=16, pretrained=False, _print=True):\n",
    "        if _print:\n",
    "            print(\"Constructing DeepLabv3+ model...\")\n",
    "            print(\"Number of classes: {}\".format(n_classes))\n",
    "            print(\"Output stride: {}\".format(os))\n",
    "            print(\"Number of Input Channels: {}\".format(nInputChannels))\n",
    "        super(DeepLabv3_plus, self).__init__()\n",
    "\n",
    "        # Atrous Conv\n",
    "        self.resnet_features = ResNet101(nInputChannels, os, pretrained=pretrained)\n",
    "\n",
    "        # ASPP\n",
    "        if os == 16:\n",
    "            rates = [1, 6, 12, 18]\n",
    "        elif os == 8:\n",
    "            rates = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.aspp1 = ASPP_module(2048, 256, rate=rates[0])\n",
    "        self.aspp2 = ASPP_module(2048, 256, rate=rates[1])\n",
    "        self.aspp3 = ASPP_module(2048, 256, rate=rates[2])\n",
    "        self.aspp4 = ASPP_module(2048, 256, rate=rates[3])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                             nn.Conv2d(2048, 256, 1, stride=1, bias=False),\n",
    "                                             nn.BatchNorm2d(256),\n",
    "                                             nn.ReLU())\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # adopt [1x1, 48] for channel reduction.\n",
    "        self.conv2 = nn.Conv2d(256, 48, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       nn.BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       nn.BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(256, n_classes, kernel_size=1, stride=1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x, low_level_features = self.resnet_features(input)\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.upsample(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.upsample(x, size=(int(math.ceil(input.size()[-2]/4)),\n",
    "                                int(math.ceil(input.size()[-1]/4))), mode='bilinear', align_corners=True)\n",
    "\n",
    "        low_level_features = self.conv2(low_level_features)\n",
    "        low_level_features = self.bn2(low_level_features)\n",
    "        low_level_features = self.relu(low_level_features)\n",
    "\n",
    "\n",
    "        x = torch.cat((x, low_level_features), dim=1)\n",
    "        print(x.shape)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.upsample(x, size=input.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def get_1x_lr_params(model):\n",
    "    \"\"\"\n",
    "    This generator returns all the parameters of the net except for\n",
    "    the last classification layer. Note that for each batchnorm layer,\n",
    "    requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n",
    "    any batchnorm parameter\n",
    "    \"\"\"\n",
    "    b = [model.resnet_features]\n",
    "    for i in range(len(b)):\n",
    "        for k in b[i].parameters():\n",
    "            if k.requires_grad:\n",
    "                yield k\n",
    "\n",
    "\n",
    "def get_10x_lr_params(model):\n",
    "    \"\"\"\n",
    "    This generator returns all the parameters for the last layer of the net,\n",
    "    which does the classification of pixel into classes\n",
    "    \"\"\"\n",
    "    b = [model.aspp1, model.aspp2, model.aspp3, model.aspp4, model.conv1, model.conv2, model.last_conv]\n",
    "    for j in range(len(b)):\n",
    "        for k in b[j].parameters():\n",
    "            if k.requires_grad:\n",
    "                yield k\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = DeepLabv3_plus(nInputChannels=3, n_classes=6, os=16, pretrained=True, _print=True)\n",
    "    model.eval()\n",
    "    image = torch.randn(2, 3, 512, 512)\n",
    "    with torch.no_grad():\n",
    "        output = model.forward(image)\n",
    "    print(output.size())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
